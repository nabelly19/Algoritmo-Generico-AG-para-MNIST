## üõ†Ô∏è Decis√µes de Projeto do Algoritmo Gen√©tico (GA) para Sele√ß√£o de Features

Este projeto utiliza um Algoritmo Gen√©tico (GA) para otimizar a sele√ß√£o de *features* (pixels) do *dataset* MNIST ($784$ *features* originais) com o objetivo de treinar um classificador **Decision Tree**. As decis√µes de projeto do GA buscam balancear a performance do modelo (acur√°cia) com a complexidade (n√∫mero de *features* selecionadas).

---

### 1. Representa√ß√£o (Cromossomo)

* **Decis√£o:** **Vetor bin√°rio de 784 posi√ß√µes**. Cada posi√ß√£o (gene) √© uma *feature*: $1$ (selecionada) ou $0$ (exclu√≠da).
* **Justificativa:** Codifica√ß√£o can√¥nica para o problema de sele√ß√£o de *features* (incluir/excluir), permitindo a explora√ß√£o de subconjuntos de **dimens√µes vari√°veis** de forma flex√≠vel.

---

### 2. Popula√ß√£o Inicial

* **Decis√£o:** Tamanho de popula√ß√£o moderado ($P \approx 50$ a $100$ indiv√≠duos). Inicializa√ß√£o **aleat√≥ria** com probabilidade de inclus√£o de *feature* $p_{init} \approx 0.3$.
* **Justificativa:** Equil√≠brio entre **diversidade** e **tempo de avalia√ß√£o**. O valor $p_{init} < 0.5$ favorece subconjuntos menores desde o in√≠cio.

---

### 3. Fun√ß√£o de Fitness

* **Decis√£o:** Fun√ß√£o de objetivo √∫nico que combina **acur√°cia** e **penaliza√ß√£o de complexidade** (n√∫mero de *features*).

    $$
    \text{fitness}(S) = \alpha \times \text{Accuracy}_{val}(S) - \beta \times \frac{\#\text{features}(S)}{784}
    $$

    (Ex: $\alpha=0.9, \beta=0.1$)
* **Justificativa:** Essencial para modelar o **trade-off** entre **desempenho** (max. acur√°cia) e **complexidade** (min. *features*), evitando a sele√ß√£o de todas as *features*. A acur√°cia ($\text{Accuracy}_{val}(S)$) √© calculada em um conjunto de valida√ß√£o interno.

---

### 4. Operadores Gen√©ticos

| Componente | Decis√£o Proposta | Par√¢metros Sugeridos | Justificativa |
| :--- | :--- | :--- | :--- |
| **Sele√ß√£o de Pais** | **Sele√ß√£o por Torneio** | Tamanho do Torneio $k=3$ ou $k=5$. **Elitismo** com $e=2$ melhores indiv√≠duos. | Garante estabilidade e progresso cont√≠nuo, crucial devido ao custo de avalia√ß√£o por indiv√≠duo. |
| **Crossover** | **Crossover Uniforme** | Taxa de Crossover $p_c \approx 0.8$. | Promove a **mistura completa** dos genes, explorando melhor as combina√ß√µes de *features* no espa√ßo de alta dimens√£o. |
| **Muta√ß√£o** | Invers√£o de Bit | Taxa de Muta√ß√£o $p_m = \frac{1}{784} \approx 0.0013$. | Mant√©m a **diversidade** e evita a converg√™ncia prematura. A taxa $1/m$ garante, em m√©dia, uma muta√ß√£o por cromossomo por gera√ß√£o. |

---

### 5. Crit√©rio de Parada

* **Decis√£o:** Parada quando:
    1.  O **n√∫mero m√°ximo de gera√ß√µes** for alcan√ßado ($G_{\text{max}} \approx 30$ a $50$).
    2.  Ou **n√£o houver melhora** no melhor indiv√≠duo ap√≥s $g_{\text{stagnant}}$ gera√ß√µes (Ex: $g_{\text{stagnant}} = 10$).
* **Justificativa:** O crit√©rio de estagna√ß√£o ($g_{\text{stagnant}}$) otimiza o tempo de execu√ß√£o, interrompendo a busca quando o algoritmo atinge uma converg√™ncia.

---

### 6. Considera√ß√µes Pr√°ticas e Log√≠stica Experimental

* **Amostragem:** Ser√° utilizada uma **amostra reduzida** do treinamento (Ex: $10.000$ exemplos) na fase de busca (c√°lculo do *fitness*) para garantir a **viabilidade computacional**.
* **Consist√™ncia:** Todas as abordagens (GA, *Wrapper* Sequencial, *Baseline*) usar√£o o mesmo modelo (**Decision Tree**) e o mesmo **Conjunto de Teste** ($10.000$ exemplos) para avalia√ß√£o final.
* **Integridade:** O conjunto de teste **n√£o** ser√° usado em nenhuma parte da busca de *features* (c√°lculo do *fitness*).
* 
### 7. Pseudoc√≥digo:

``` csharp

Input: 
    X_train_full (n_train √ó 784) ‚Äì conjunto de treinamento completo usado para busca
    y_train_full (n_train) ‚Äì r√≥tulos correspondentes
    X_test (n_test √ó 784), y_test (n_test) ‚Äì conjunto de teste (n√£o usado na busca)
Parameters:
    P = tamanho da popula√ß√£o (ex: 80)
    G_max = n√∫mero m√°ximo de gera√ß√µes (ex: 40)
    g_stagnant = n√∫mero m√°ximo de gera√ß√µes sem melhoria (ex: 10)
    p_init = probabilidade inicial de sele√ß√£o de cada feature (ex: 0.3)
    p_crossover = taxa de crossover (ex: 0.8)
    p_mutation = taxa de muta√ß√£o por gene (ex: 1/784 ‚âà 0.0013)
    elitism_size = n√∫mero de melhores indiv√≠duos que passam direto (ex: 2)
    Œ±, Œ≤ = pesos da fun√ß√£o de fitness (ex: Œ±=0.9, Œ≤=0.1)

Procedure:
1. Dividir X_train_full, y_train_full em:
       ‚Äì X_train_search, y_train_search (por exemplo 80% dos dados) ‚Äì para treinar modelo durante GA
       ‚Äì X_val_search, y_val_search (por exemplo 20%) ‚Äì para validar cada indiv√≠duo e calcular acur√°cia

2. Inicializar popula√ß√£o Pop = []  
   For i in 1 ‚Ä¶ P:
       individual.chromosome = vetor de comprimento 784 com cada gene = 1 com probabilidade p_init, ou 0 com probabilidade (1-p_init)
       Pop.append(individual)

3. Avaliar fitness de cada indiv√≠duo em Pop:
   For cada individual ind in Pop:
       seletor = indices onde ind.chromosome == 1  
       Treinar modelo DecisionTreeClassifier() em X_train_search[:, seletor], y_train_search  
       Fazer predi√ß√£o em X_val_search[:, seletor] ‚Üí acur√°cia = acc  
       pct = (#features_selected) / 784  
       fitness = Œ± * acc - Œ≤ * pct  
       ind.fitness = fitness  
   Registrar melhor_indiv√≠duo = indiv√≠duo com maior fitness  
   melhor_fitness_historico = melhor_indiv√≠duo.fitness  
   generacao = 0  
   geracoes_sem_melhoria = 0

4. Enquanto (generacao < G_max) e (geracoes_sem_melhoria < g_stagnant):
       generacao += 1
       
       ## 4.1 ‚Äì Sele√ß√£o:
       NovaPop = []
       Copiar os elitism_size melhores indiv√≠duos de Pop para NovaPop (elitismo)
       
       Enquanto (|NovaPop| < P):
           Selecionar ‚Äúpai1‚Äù mediante torneio de tamanho k (ex: 3) da Pop  
           Selecionar ‚Äúpai2‚Äù da mesma forma  
           
           ## 4.2 ‚Äì Crossover:
           Gerar dois filhos filho1, filho2:
               Com probabilidade p_crossover:  
                   Para cada gene j = 1 ‚Ä¶ 784:
                       se rand() < 0.5 ent√£o filho1.gene[j] = pai1.gene[j], filho2.gene[j] = pai2.gene[j]
                       else filho1.gene[j] = pai2.gene[j], filho2.gene[j] = pai1.gene[j]
               Caso contr√°rio (sem crossover) filho1 = pai1.copy(), filho2 = pai2.copy()
           
           ## 4.3 ‚Äì Muta√ß√£o:
           Para cada filho in {filho1, filho2}:
               Para each gene j = 1 ‚Ä¶ 784:
                   if rand() < p_mutation then filho.gene[j] = 1 - filho.gene[j]
               Garantir que pelo menos 1 gene = 1 (opcional: se todos zeros, setar um gene aleat√≥rio para 1)
           
           Adicionar filho1, filho2 em NovaPop (at√© preencher P)
       
       Pop = NovaPop  (nova gera√ß√£o)
       
       ## 4.4 ‚Äì Avaliar fitness da nova popula√ß√£o:
       Para cada indiv√≠duo ind in Pop que ainda n√£o tenha fitness calculado:
           seletor = indices onde ind.chromosome == 1  
           Treinar DecisionTreeClassifier em X_train_search[:, seletor], y_train_search  
           Validar em X_val_search[:, seletor] ‚Üí acc  
           pct = (#features_selected) / 784  
           fitness = Œ± * acc - Œ≤ * pct  
           ind.fitness = fitness  
       
       Encontrar melhor indiv√≠duo da gera√ß√£o: if melhor_indiv√≠duo_gen.fitness > melhor_fitness_historico:
           melhor_indiv√≠duo = melhor_indiv√≠duo_gen  
           melhor_fitness_historico = melhor_indiv√≠duo.fitness  
           geracoes_sem_melhoria = 0
       else:
           geracoes_sem_melhoria += 1

5. Ao fim do loop: melhor_indiv√≠duo.chromosome define o **subconjunto de features final** selecionadas pelo GA.

6. **Treinamento final do modelo**:  
   seletor_final = indices onde melhor_indiv√≠duo.chromosome == 1  
   Treinar DecisionTreeClassifier em *todo* X_train_full[:, seletor_final] e y_train_full  
   Fazer previs√£o em X_test[:, seletor_final], y_test ‚Üí obter acur√°cia_final

7. **Relat√≥rio**:  
   ‚Äì Acur√°cia no teste = acur√°cia_final  
   ‚Äì Porcentagem de features selecionadas = (#seletor_final) / 784 √ó 100%  
   ‚Äì Tempo de busca = tempo gasto na fase 1-5  
   ‚Äì Tempo de treinamento = tempo gasto na fase 6  

Output: melhor_indiv√≠duo, acur√°cia_final, porcentagem_features, tempos.

End.
